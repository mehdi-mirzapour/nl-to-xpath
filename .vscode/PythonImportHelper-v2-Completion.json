[
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "segment",
        "importPath": "sentence_segmentor",
        "description": "sentence_segmentor",
        "isExtraImport": true,
        "detail": "sentence_segmentor",
        "documentation": {}
    },
    {
        "label": "classify",
        "importPath": "task_mapper",
        "description": "task_mapper",
        "isExtraImport": true,
        "detail": "task_mapper",
        "documentation": {}
    },
    {
        "label": "extract_xpath_pattern",
        "importPath": "xpath_extractor",
        "description": "xpath_extractor",
        "isExtraImport": true,
        "detail": "xpath_extractor",
        "documentation": {}
    },
    {
        "label": "sync_playwright",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "sync_playwright",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "process_html_query",
        "importPath": "rag_html",
        "description": "rag_html",
        "isExtraImport": true,
        "detail": "rag_html",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "ChatMistralAI",
        "importPath": "langchain_mistralai",
        "description": "langchain_mistralai",
        "isExtraImport": true,
        "detail": "langchain_mistralai",
        "documentation": {}
    },
    {
        "label": "ChatMistralAI",
        "importPath": "langchain_mistralai",
        "description": "langchain_mistralai",
        "isExtraImport": true,
        "detail": "langchain_mistralai",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "llama_index.core",
        "description": "llama_index.core",
        "isExtraImport": true,
        "detail": "llama_index.core",
        "documentation": {}
    },
    {
        "label": "VectorStoreIndex",
        "importPath": "llama_index.core",
        "description": "llama_index.core",
        "isExtraImport": true,
        "detail": "llama_index.core",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "llama_index.core",
        "description": "llama_index.core",
        "isExtraImport": true,
        "detail": "llama_index.core",
        "documentation": {}
    },
    {
        "label": "MistralAIEmbedding",
        "importPath": "llama_index.embeddings.mistralai",
        "description": "llama_index.embeddings.mistralai",
        "isExtraImport": true,
        "detail": "llama_index.embeddings.mistralai",
        "documentation": {}
    },
    {
        "label": "PineconeVectorStore",
        "importPath": "llama_index.vector_stores.pinecone",
        "description": "llama_index.vector_stores.pinecone",
        "isExtraImport": true,
        "detail": "llama_index.vector_stores.pinecone",
        "documentation": {}
    },
    {
        "label": "Pinecone",
        "importPath": "pinecone",
        "description": "pinecone",
        "isExtraImport": true,
        "detail": "pinecone",
        "documentation": {}
    },
    {
        "label": "ServerlessSpec",
        "importPath": "pinecone",
        "description": "pinecone",
        "isExtraImport": true,
        "detail": "pinecone",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "RunnableLambda",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnableLambda",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnableLambda",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "log = logging.getLogger(\"rich\")\n# ------------------------\n# Parse command-line argument for instruction file\n# ------------------------\nparser = argparse.ArgumentParser(description=\"Run browser instructions from a file.\")\nparser.add_argument(\"instruction_file\", help=\"Path to the instruction text file.\")\nargs = parser.parse_args()\n# ------------------------\n# Read instructions from file\n# ------------------------",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Run browser instructions from a file.\")\nparser.add_argument(\"instruction_file\", help=\"Path to the instruction text file.\")\nargs = parser.parse_args()\n# ------------------------\n# Read instructions from file\n# ------------------------\nwith open(args.instruction_file, \"r\") as f:\n    instruction = f.read().strip()\n# Wrap input in JSON structure\nuser_data = {\"user_inputs\": instruction}",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "args = parser.parse_args()\n# ------------------------\n# Read instructions from file\n# ------------------------\nwith open(args.instruction_file, \"r\") as f:\n    instruction = f.read().strip()\n# Wrap input in JSON structure\nuser_data = {\"user_inputs\": instruction}\nlog.info(f\"🗃️  User Input as JSON:\\n{json.dumps(user_data, indent=2)}\")\n# Convert NL to structured instructions",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "user_data",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "user_data = {\"user_inputs\": instruction}\nlog.info(f\"🗃️  User Input as JSON:\\n{json.dumps(user_data, indent=2)}\")\n# Convert NL to structured instructions\noutput = segment(instruction, model)\nlog.info(\"🧩 Sentence Segmentor Output:\\n\" + str(output))\n# Classify the instructions\noutput = classify(output, model)\nlog.info(\"🧠 Task Mapper Output:\\n\" + str(output))\n# Save to JSON file\nwith open(\"resources/docs/classification.json\", \"w\") as f:",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "output = segment(instruction, model)\nlog.info(\"🧩 Sentence Segmentor Output:\\n\" + str(output))\n# Classify the instructions\noutput = classify(output, model)\nlog.info(\"🧠 Task Mapper Output:\\n\" + str(output))\n# Save to JSON file\nwith open(\"resources/docs/classification.json\", \"w\") as f:\n    json.dump(output, f, indent=4)\nwith open(\"resources/docs/classification.json\", \"r\") as f:\n    out = json.load(f)",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "src.agentic_app",
        "description": "src.agentic_app",
        "peekOfCode": "output = classify(output, model)\nlog.info(\"🧠 Task Mapper Output:\\n\" + str(output))\n# Save to JSON file\nwith open(\"resources/docs/classification.json\", \"w\") as f:\n    json.dump(output, f, indent=4)\nwith open(\"resources/docs/classification.json\", \"r\") as f:\n    out = json.load(f)\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=False)\n    page = browser.new_page()",
        "detail": "src.agentic_app",
        "documentation": {}
    },
    {
        "label": "os.environ[\"OPENAI_API_KEY\"]",
        "kind": 5,
        "importPath": "src.models",
        "description": "src.models",
        "peekOfCode": "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\nmodel = ChatOpenAI(model=\"gpt-4\", temperature=0)\n# model = ChatMistralAI(model=\"mistral-large-latest\", temperature=0)",
        "detail": "src.models",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "src.models",
        "description": "src.models",
        "peekOfCode": "model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n# model = ChatMistralAI(model=\"mistral-large-latest\", temperature=0)",
        "detail": "src.models",
        "documentation": {}
    },
    {
        "label": "initialize_pinecone",
        "kind": 2,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "def initialize_pinecone(index_name, dimension=1024, metric=\"cosine\", cloud=\"aws\", region=\"us-east-1\", namespace=\"default\"):\n    if not pinecone_api_key:\n        raise ValueError(\"Pinecone API key is not provided.\")\n    try:\n        pc = Pinecone(api_key=pinecone_api_key)\n    except Exception as e:\n        raise ConnectionError(f\"Failed to initialize Pinecone client: {e}\")\n    if index_name in pc.list_indexes().names():\n        index = pc.Index(index_name)\n        # Check index configuration",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "chunk_html",
        "kind": 2,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "def chunk_html(html_content, chunk_size):\n    chunks = []\n    for i in range(0, len(html_content), chunk_size):\n        chunk = html_content[i:i + chunk_size]\n        chunks.append(chunk)\n    return chunks\n# Find most similar chunk\ndef find_similar_chunk(html_content, query, chunk_size= max_token_limitation, index_name=\"default-index\"):\n    # Set Mistral AI embedding model (calls Mistral API)\n    Settings.embed_model = MistralAIEmbedding(",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "find_similar_chunk",
        "kind": 2,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "def find_similar_chunk(html_content, query, chunk_size= max_token_limitation, index_name=\"default-index\"):\n    # Set Mistral AI embedding model (calls Mistral API)\n    Settings.embed_model = MistralAIEmbedding(\n        model_name=\"mistral-embed\",\n        api_key=mistral_api_key\n    )\n    # Disable LLM since it's not needed for similarity search\n    Settings.llm = None\n    # Initialize Pinecone\n    pinecone_index = initialize_pinecone(index_name)",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "process_html_query",
        "kind": 2,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "def process_html_query(html_content, query, chunk_size=max_token_limitation*3, index_name=os.getenv(\"PINECONE_INDEX_NAME\")\n):\n    if len(html_content) < (max_token_limitation*2.5) :\n      return html_content\n    result = find_similar_chunk(html_content, query, chunk_size, index_name)\n    output = f\"\"\"Number of chunks created: {result['total_chunks']}\nSelected chunk index: {result['selected_chunk_index']}\nSimilarity score: {result['similarity_score']:.4f}\n\"\"\"\n    print(output)",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "mistral_api_key",
        "kind": 5,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\npinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\nmax_token_limitation = int(os.getenv(\"MAX_TOKEN_LIMITATION\", 12000))  # Default to 12000 if not set\n# Validate environment variables\nif not mistral_api_key:\n    raise ValueError(\"MISTRAL_API_KEY not set in environment.\")\nif not pinecone_api_key:\n    raise ValueError(\"PINECONE_API_KEY not set in environment.\")\ndef initialize_pinecone(index_name, dimension=1024, metric=\"cosine\", cloud=\"aws\", region=\"us-east-1\", namespace=\"default\"):\n    if not pinecone_api_key:",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "pinecone_api_key",
        "kind": 5,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\nmax_token_limitation = int(os.getenv(\"MAX_TOKEN_LIMITATION\", 12000))  # Default to 12000 if not set\n# Validate environment variables\nif not mistral_api_key:\n    raise ValueError(\"MISTRAL_API_KEY not set in environment.\")\nif not pinecone_api_key:\n    raise ValueError(\"PINECONE_API_KEY not set in environment.\")\ndef initialize_pinecone(index_name, dimension=1024, metric=\"cosine\", cloud=\"aws\", region=\"us-east-1\", namespace=\"default\"):\n    if not pinecone_api_key:\n        raise ValueError(\"Pinecone API key is not provided.\")",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "max_token_limitation",
        "kind": 5,
        "importPath": "src.rag_html",
        "description": "src.rag_html",
        "peekOfCode": "max_token_limitation = int(os.getenv(\"MAX_TOKEN_LIMITATION\", 12000))  # Default to 12000 if not set\n# Validate environment variables\nif not mistral_api_key:\n    raise ValueError(\"MISTRAL_API_KEY not set in environment.\")\nif not pinecone_api_key:\n    raise ValueError(\"PINECONE_API_KEY not set in environment.\")\ndef initialize_pinecone(index_name, dimension=1024, metric=\"cosine\", cloud=\"aws\", region=\"us-east-1\", namespace=\"default\"):\n    if not pinecone_api_key:\n        raise ValueError(\"Pinecone API key is not provided.\")\n    try:",
        "detail": "src.rag_html",
        "documentation": {}
    },
    {
        "label": "extract_json_from_codeblock",
        "kind": 2,
        "importPath": "src.sentence_segmentor",
        "description": "src.sentence_segmentor",
        "peekOfCode": "def extract_json_from_codeblock(output: str) -> str:\n    \"\"\"Remove code block markdown from model output.\"\"\"\n    lines = output.strip().splitlines()\n    if lines[0].strip().startswith(\"```\"):\n        lines = lines[1:]\n    if lines and lines[-1].strip().startswith(\"```\"):\n        lines = lines[:-1]\n    json_str = \"\\n\".join(lines)\n    return json.loads(json_str)\ndef segment(instructions: str, model) -> str:",
        "detail": "src.sentence_segmentor",
        "documentation": {}
    },
    {
        "label": "segment",
        "kind": 2,
        "importPath": "src.sentence_segmentor",
        "description": "src.sentence_segmentor",
        "peekOfCode": "def segment(instructions: str, model) -> str:\n    \"\"\"Convert NL input into line-by-line web automation steps using OpenAI.\"\"\"\n    load_dotenv()\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    if not api_key:\n        raise ValueError(\"OPENAI_API_KEY not set in environment.\")\n    os.environ[\"OPENAI_API_KEY\"] = api_key\n    template = \"\"\"\nYou are a helpful assistant that takes a block of natural language describing a web-based task, and converts it into a list of individual, precise, and executable web automation steps.\nEach action should be:",
        "detail": "src.sentence_segmentor",
        "documentation": {}
    },
    {
        "label": "extract_json_from_codeblock",
        "kind": 2,
        "importPath": "src.task_mapper",
        "description": "src.task_mapper",
        "peekOfCode": "def extract_json_from_codeblock(output: str) -> dict:\n    \"\"\"Extract and parse JSON from a code block in LLM output.\"\"\"\n    lines = output.strip().splitlines()\n    if lines and lines[0].strip().startswith(\"```\"):\n        lines = lines[1:]\n    if lines and lines[-1].strip().startswith(\"```\"):\n        lines = lines[:-1]\n    json_str = \"\\n\".join(lines)\n    return json.loads(json_str)\ndef classify(instructions: str, model) -> dict:",
        "detail": "src.task_mapper",
        "documentation": {}
    },
    {
        "label": "classify",
        "kind": 2,
        "importPath": "src.task_mapper",
        "description": "src.task_mapper",
        "peekOfCode": "def classify(instructions: str, model) -> dict:\n    \"\"\"Classify natural language instructions into web automation actions using MistralAI.\"\"\"\n    load_dotenv()\n    api_key = os.getenv(\"MISTRAL_API_KEY\")\n    if not api_key:\n        raise ValueError(\"MISTRAL_API_KEY not set in environment.\")\n    os.environ[\"MISTRAL_API_KEY\"] = api_key\n    prompt_template = \"\"\"\nYou are an intelligent instruction classifier.\nYour task is to read a long natural language input where each line represents an instruction to be executed in a web automation context.",
        "detail": "src.task_mapper",
        "documentation": {}
    },
    {
        "label": "extract_url",
        "kind": 2,
        "importPath": "src.utils",
        "description": "src.utils",
        "peekOfCode": "def extract_url(text):\n    pattern = r'(https?://[^\\s\\'\"]+|localhost:\\d+[^\\s\\'\"]*)'\n    match = re.search(pattern, text)\n    return match.group(0) if match else None\ndef load_instructions_from_file(json_path: str):\n    \"\"\"Load instruction data from a JSON file.\"\"\"\n    file_path = Path(json_path)\n    if not file_path.exists():\n        raise FileNotFoundError(f\"File not found: {json_path}\")\n    with open(file_path, 'r', encoding='utf-8') as f:",
        "detail": "src.utils",
        "documentation": {}
    },
    {
        "label": "load_instructions_from_file",
        "kind": 2,
        "importPath": "src.utils",
        "description": "src.utils",
        "peekOfCode": "def load_instructions_from_file(json_path: str):\n    \"\"\"Load instruction data from a JSON file.\"\"\"\n    file_path = Path(json_path)\n    if not file_path.exists():\n        raise FileNotFoundError(f\"File not found: {json_path}\")\n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f) \n    return data",
        "detail": "src.utils",
        "documentation": {}
    },
    {
        "label": "extract_json_from_codeblock",
        "kind": 2,
        "importPath": "src.xpath_extractor",
        "description": "src.xpath_extractor",
        "peekOfCode": "def extract_json_from_codeblock(output: str) -> str:\n    \"\"\"Remove code block markdown from model output.\"\"\"\n    lines = output.strip().splitlines()\n    if lines[0].strip().startswith(\"```\"):\n        lines = lines[1:]\n    if lines and lines[-1].strip().startswith(\"```\"):\n        lines = lines[:-1]\n    return \"\\n\".join(lines)\ndef extract_xpath_pattern(instruction: str, html: str, model) -> str:\n    \"\"\"Run the instruction + HTML through Mistral and return JSON result.\"\"\"",
        "detail": "src.xpath_extractor",
        "documentation": {}
    },
    {
        "label": "extract_xpath_pattern",
        "kind": 2,
        "importPath": "src.xpath_extractor",
        "description": "src.xpath_extractor",
        "peekOfCode": "def extract_xpath_pattern(instruction: str, html: str, model) -> str:\n    \"\"\"Run the instruction + HTML through Mistral and return JSON result.\"\"\"\n    # Prompt template\n    template = \"\"\"\nYou are an expert UI assistant that converts natural language commands into web automation step.\nYou will be given:\n- A web page's full HTML\n- A natural language instruction from the user\nYour job:\n- Translate the instruction into one step, each using an action from only both category: \"click\", \"fill\" all lowercase.",
        "detail": "src.xpath_extractor",
        "documentation": {}
    }
]